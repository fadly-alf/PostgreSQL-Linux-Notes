CREATE QUERY:

1. ACCESS METHOD: untuk cara penyimpanan index
CREATE ACCESS METHOD my_method TYPE INDEX HANDLER my_handler_function;

2. AGGREGATE: menghitung nilai tunggal dari sekumpulan nilai data, seperti jumlah, rata-rata, nilai minimum, atau maksimum
CREATE AGGREGATE sum_int8(bigint) (SFUNC = int8pl, STYPE = bigint, INITCOND = '0');

3. CAST: membuat konversi antar tipe data
CREATE CAST (varchar AS int) WITH FUNCTION varchar_to_int(varchar) AS ASSIGNMENT;

4. COLLATION: aturan pengurutan string
CREATE COLLATION german (LOCALE = 'de_DE.utf8');

5. CONVERSION konversi karakter encoding
CREATE CONVERSION myconv FOR 'UTF8' TO 'LATIN1' FROM myfunc;

6. DATABASE: sebuah DATABASE
CREATE DATABASE nama_db;

7. DOMAIN: tipe data dengan aturan sendiri
CREATE DOMAIN positive_int AS int CHECK (VALUE > 0);

8. EVENT TRIGGER: Trigger untuk event DDL
CREATE EVENT TRIGGER ddl_trigger ON ddl_command_start EXECUTE FUNCTION log_ddl();

9. EXTENSION: membuat sebuah EXTENSION
CREATE EXTENSION IF NOT EXISTS "uuid-ossp";

10. FOREIGN DATA WRAPPER: mengakses data eksternal
CREATE FOREIGN DATA WRAPPER my_fdw;

11. FOREIGN TABLE: membuat table yang merupakan table eksternal di server lain, jadi perlu dibuat dulu DDL table eksternal nya, nanti hanya perlu query saja seperti biasa
CREATE FOREIGN TABLE ft_users (id int, name text) SERVER my_server OPTIONS (table_name 'remote_users');

12. FUNCTION:  objek database yang berisi satu set perintah SQL atau perintah yang ditulis dalam bahasa prosedural (seperti PL/pgSQL) yang dapat dieksekusi dan mengembalikan nilai tunggal (skalar) atau satu set baris (tabel).
CREATE [OR REPLACE] FUNCTION nama_fungsi(parameter1 tipe_data, parameter2 tipe_data, ...)
RETURNS tipe_data_kembalian -- atau RETURNS TABLE(...) atau RETURNS SETOF tipe_data
AS $$
-- Badan fungsi (logika, deklarasi variabel, perintah SQL)
BEGIN
    -- Logika ...
    RETURN nilai;
END;
$$ LANGUAGE plpgsql;

SELECT nama_fungsi(nilai_parameter1, nilai_parameter2);
SELECT * FROM nama_fungsi(nilai_parameter1); -- Jika function mengembalikan set of rows (RETURNS TABLE atau SETOF)

13. GROUP: alias lama untuk role GROUP
CREATE GROUP devs;

14. INDEX: membuat index untuk mempercepat pencarian
CREATE INDEX nama_index ON nama_table(nama_kolom);

15. LANGUAGE: membuat 
CREATE LANGUAGE plpgsql;

16. MATERIALIZED VIEW: view yang disimpan secara fisik di harddisk
CREATE MATERIALIZED VIEW active_users AS SELECT * FROM users WHERE active = true;

17. OPERATOR
CREATE OPERATOR === (LEFTARG = int, RIGHTARG = int, PROCEDURE = int4eq);

18. OR REPLACE: untuk mengganti objek
CREATE OR REPLACE FUNCTION hello() RETURNS text AS $$ SELECT 'Hello World'; $$ LANGUAGE sql;

19. POLICY (Row Level Security)
CREATE POLICY user_policy ON users FOR SELECT USING (current_user = username);

20. PROCEDURE
CREATE PROCEDURE log_message(msg text)
LANGUAGE plpgsql
AS $$
BEGIN
    INSERT INTO logs(message) VALUES (msg);
END;
$$;


21. PUBLICATION (Log Reps)
CREATE PUBLICATION my_pub FOR TABLE users;

22. ROLE 
CREATE ROLE nama_role LOGIN PASSWORD 'password';

23. RULE: mendefinisikan suatu tindakan yang harus dilakukan oleh sistem sebelum suatu query dieksekusi.
CREATE [ OR REPLACE ] RULE nama_rule AS ON event_type TO nama_tabel [ WHERE condition ] DO [ INSTEAD ] action;
CREATE RULE no_delete AS ON DELETE TO users DO INSTEAD NOTHING;

24. SCHEMA: 
CREATE SCHEMA nama_schema;

25. SEQUENCE:  objek database yang digunakan untuk menghasilkan nilai numerik unik secara otomatis (biasanya integer).
CREATE SEQUENCE order_seq START 1 INCREMENT 1;
CREATE SEQUENCE nama_sequence
    INCREMENT BY 1        -- Berapa banyak nilai bertambah (default 1)
    MINVALUE 1            -- Nilai minimum (default 1)
    START WITH 1          -- Nilai awal
    CACHE 20;             -- Berapa banyak nilai yang disimpan di memori untuk akses cepat

- Mengambil Nilai Berikutnya
SELECT nextval('nama_sequence');

- Mengambil Nilai Saat ini 
SELECT currval('nama_sequence');

26. SERVER
CREATE SERVER my_server FOREIGN DATA WRAPPER my_fdw OPTIONS (host 'localhost', dbname 'otherdb');

27. STATISTIC
CREATE STATISTICS user_stats (dependencies) ON age, city FROM users;

28. SUBSCRIPTION (Log Reps)
CREATE SUBSCRIPTION nama_sub CONNECTION 'dbname=source host=127.0.0.1 user=rep password=pass' PUBLICATION nama_pub;

29. TABLE
CREATE TABLE products (
    id SERIAL PRIMARY KEY,
    name text,
    price numeric
);

30. TABLESPACE: lokasi penyimpanan fisik pada sistem file yang digunakan untuk menyimpan file data, indeks, dan objek database lainnya.
CREATE TABLESPACE fastdisk LOCATION '/mnt/ssd1/pgdata';
CREATE TABLESPACE nama_tablespace OWNER nama_user LOCATION '/path/ke/direktori/fisik';

- Menggunakan TABLESPACE
CREATE TABLE nama_tabel (kolom1 INT, kolom2 VARCHAR(255)) TABLESPACE nama_tablespace;

- Membuat index di TABLESPACE
CREATE INDEX nama_indeks ON nama_tabel (kolom_indeks) TABLESPACE nama_tablespace;

- Membuat database di TABLESPACE tertentu
CREATE DATABASE nama_database TABLESPACE nama_tablespace;

31. TEMP/TEMPORARY: Tabel Sementara (Temporary Tables) atau Files Temporer (Temporary Files) yang digunakan oleh sistem saat memproses query yang kompleks.
CREATE TEMP TABLE temp_data (id int, value text);

32. TEXT SEARCH: melakukan pencarian dokumen atau teks berbasis natural language 
CREATE TEXT SEARCH CONFIGURATION my_english (COPY = pg_catalog.english);

33. TRANSFORM: mengubah, membersihkan, memvalidasi, dan menggabungkan data mentah yang telah diekstrak dari sumber data (Langkah E) menjadi format yang sesuai dan siap untuk dimuat ke dalam sistem tujuan, seperti Data Warehouse atau Data Mart (Langkah L).
CREATE TRANSFORM FOR jsonb LANGUAGE plpgsql (FROM SQL WITH FUNCTION jsonb_in(cstring), TO SQL WITH FUNCTION jsonb_out(jsonb));

34. TRIGGER: Trigger adalah objek basis data yang secara otomatis menjalankan fungsi atau prosedur tertentu sebagai respons terhadap peristiwa (event) tertentu pada suatu tabel.
CREATE TRIGGER update_timestamp BEFORE UPDATE ON users FOR EACH ROW EXECUTE FUNCTION update_modified_column();

35. TYPE: 
CREATE TYPE mood AS ENUM ('happy', 'sad', 'ok');

36. UNIQUE:
 CREATE TABLE accounts (
    id serial,
    email text UNIQUE
);

37. UNLOGGED
CREATE UNLOGGED TABLE cache_data (
    key text,
    value text
);

38. USER 
CREATE USER appuser WITH PASSWORD 'securepass';

39. USER MAPPING FOR: memetakan kredensial (nama pengguna dan kata sandi) dari satu pengguna basis data lokal ke kredensial pengguna di basis data atau sistem eksternal. Fitur ini bekerja bersama dengan ekstensi Foreign Data Wrapper (FDW).
CREATE USER MAPPING FOR appuser SERVER my_server OPTIONS (user 'remoteuser', password 'remotepass');

40. VIEW: view Sementara
CREATE VIEW active_users AS SELECT * FROM users WHERE active = true;

41. BEGIN, COMMIT, ROLLBACK
- BEGIN
BEGIN;
UPDATE accounts SET balance = balance - 100 WHERE user_id = 1;
UPDATE accounts SET balance = balance + 100 WHERE user_id = 2;
COMMIT;

- ROLLBACK
BEGIN;
INSERT INTO logs (message) VALUES ('Mencoba operasi...');
-- Operasi gagal
ROLLBACK;

42. SAVEPOINT: Menentukan titik di dalam transaksi untuk bisa kembali (rollback) tanpa membatalkan seluruh transaksi.
BEGIN;
INSERT INTO users (name) VALUES ('Andi');
SAVEPOINT before_update;
UPDATE users SET name = 'Budi' WHERE name = 'Andi';
ROLLBACK TO SAVEPOINT before_update; -- Perubahan 'Budi' dibatalkan, 'Andi' tetap ada
COMMIT;

43. RELEASE: Menghapus savepoint dari transaksi. Perubahan yang dilakukan setelah savepoint akan tetap ada.
BEGIN;
INSERT INTO users (name) VALUES ('Cici');
SAVEPOINT s1;
INSERT INTO users (name) VALUES ('Deni');
RELEASE SAVEPOINT s1; -- s1 dihapus, kedua INSERT akan di-commit
COMMIT;

44. SELECT: Mengambil data dari satu atau lebih tabel. Ini adalah perintah DML yang paling sering digunakan.
SELECT first_name, last_name FROM employees WHERE department = 'Sales' ORDER BY last_name;

45. INSERT INTO: Menambahkan baris baru ke dalam tabel.
INSERT INTO products (name, price) VALUES ('Laptop', 1200);

46. UPDATE: Memodifikasi data di baris yang sudah ada.
UPDATE products SET price = 1300 WHERE name = 'Laptop';

47. DELETE FROM: Menghapus baris dari tabel.
DELETE FROM products WHERE price > 2000;

48. MERGE INTO: Menggabungkan operasi INSERT, UPDATE, dan DELETE menjadi satu perintah berdasarkan kondisi kecocokan antara tabel sumber dan tabel target.
MERGE INTO inventory AS t
USING new_products AS s
ON t.product_id = s.product_id
WHEN MATCHED THEN
  UPDATE SET stock = t.stock + s.stock
WHEN NOT MATCHED THEN
  INSERT (product_id, name, stock) VALUES (s.product_id, s.name, s.stock);

49. TRUNCATE: Menghapus semua baris dari tabel dengan sangat cepat. Perintah ini tidak memicu trigger level baris.
TRUNCATE TABLE staging_data;

50. COMMENT: Menambahkan komentar pada objek database untuk tujuan dokumentasi.
COMMENT ON COLUMN users.id IS 'Primary key untuk tabel users.';

51. RENAME: mengganti nama
ALTER TABLE table_name RENAME TO new_name;

52. ANALYZE: Mengumpulkan statistik tentang isi tabel untuk membantu query planner membuat rencana eksekusi yang lebih baik.
ANALYZE orders;

53. VACUUM: Mereklamasi ruang penyimpanan yang digunakan oleh baris yang telah dihapus atau diperbarui.
- VACUUM: Jenis vacuum dasar yang menandai ruang yang ditempati tupel mati sebagai tersedia untuk digunakan kembali. Proses ini tidak mengubah ukuran file data, tetapi memungkinkan data baru ditulis ke ruang kosong tersebut. Vacuum biasa umumnya tidak mengunci tabel dalam waktu lama.
VACUUM public.sales;

- VACUUM FULL: Proses ini menulis ulang seluruh isi tabel ke file baru di disk, mengembalikan ruang kosong ke sistem operasi dan bisa mengurangi ukuran file tabel. Namun, vacuum full membutuhkan penguncian eksklusif yang memblokir operasi baca/tulis selama proses berjalan dan membutuhkan ruang disk tambahan sementara.

- Autovacuum: Proses otomatis yang berjalan di latar belakang, memantau database dan menjalankan vacuum secara otomatis saat dibutuhkan untuk mencegah bloat (pemborosan ruang penyimpanan akibat tupel mati yang menumpuk). Autovacuum membantu menjaga performa tanpa perlu intervensi manual.

- Paralel Vacuum:  Pada beberapa versi dan konfigurasi, vacuum bisa dijalankan dengan pekerja paralel yang melakukan penyedotan pada indeks dan pembersihan secara bersamaan, meningkatkan kecepatan vacuum.

54. CLUSTER: Mengurutkan ulang baris dalam tabel berdasarkan indeks, yang dapat meningkatkan performa untuk query yang sering mengakses baris yang berdekatan.
CLUSTER users USING idx_users_id;

55. REINDEX: Membangun kembali satu atau semua indeks pada tabel atau database untuk mengoptimalkan performa.
REINDEX TABLE employees;

56. EXPLAIN: Menampilkan rencana eksekusi dari suatu query tanpa benar-benar menjalankannya. Sangat penting untuk mengoptimalkan performa.
EXPLAIN ANALYZE SELECT * FROM large_table WHERE column = 'value';

57. REFRESH MATERIALIZED VIEW: Memperbarui data dalam Materialized View dengan mengeksekusi ulang query definisinya.
REFRESH MATERIALIZED VIEW CONCURRENTLY nama_view;

58. COPY: Menyalin data antara tabel dan file. Sangat cepat untuk impor/ekspor data massal.
COPY products FROM 'products_data.csv' DELIMITER ',' CSV HEADER;

59. SHOW: Menampilkan nilai dari parameter konfigurasi PostgreSQL.
SHOW work_mem;
SHOW data_directory;

60. SET: Mengubah nilai parameter konfigurasi untuk sesi saat ini.
SET work_mem = '16MB';
SET search_pat TO nama_schema;

PostgreSQL BINARIES:

1. initdb
Penjelasan: Membuat klaster data PostgreSQL baru (Data Directory). Ini adalah langkah pertama untuk membuat instance server baru.
Cara pakai: initdb [OPTIONS] -D DATADADIR -D, --pgdata: Jalur ke direktori tempat data akan disimpan. -E, --encoding: Encoding karakter default (misalnya UTF8). --locale: Pengaturan lokal (locale) yang akan digunakan.

2. postgres
Penjelasan: Program server database utama. Tidak dijalankan langsung oleh pengguna, tetapi melalui pg_ctl atau layanan sistem.
Cara pakai: postgres [OPTIONS] -D DATADIR -D: Jalur Data Directory (wajib). -c name=value: Mengatur parameter konfigurasi.

3. pg_ctl
Penjelasan: Alat kontrol utilitas untuk memulai, menghentikan, memuat ulang konfigurasi, dan melihat status server PostgreSQL.
Cara pakai: pg_ctl command -D DATADIR [OPTIONS] start: Memulai server. stop: Menghentikan server. restart: Menghentikan dan memulai ulang. reload: Memuat ulang file konfigurasi (postgresql.conf). status: Menampilkan status server.

4. createdb
Penjelasan: Membuat database PostgreSQL baru.
Cara pakai: createdb [OPTIONS] dbname -O, --owner: Menentukan pemilik database. -E, --encoding: Encoding database. -T, --template: Database template yang akan digunakan.

5. dropdb
Penjelasan: Menghapus database PostgreSQL secara permanen.
Cara pakai: dropdb [OPTIONS] dbname -i, --interactive: Meminta konfirmasi sebelum menghapus.

6. createuser
Penjelasan: Membuat peran (role) PostgreSQL baru.	
Cara pakai: createuser [OPTIONS] rolename --superuser: Memberikan hak superuser. --createdb: Memberikan izin untuk membuat database. --password: Meminta kata sandi secara interaktif.

7. dropuser
Penjelasan: Menghapus peran (role) PostgreSQL.	
Cara pakai: dropuser [OPTIONS] rolename -i, --interactive: Meminta konfirmasi sebelum menghapus.

8. psql
Penjelasan: Klien terminal interaktif untuk PostgreSQL. Digunakan untuk menjalankan query SQL, administrasi, dan skrip.	
Cara pakai: psql [OPTIONS] [dbname [username]] -c, --command: Menjalankan satu perintah SQL dan keluar. -f, --file: Menjalankan perintah SQL dari file. -l, --list: Mencantumkan semua database.

9. pg_isready	
Penjelasan: Memeriksa status koneksi server PostgreSQL, sangat berguna untuk skrip atau pemantauan.	
Cara pakai: pg_isready [OPTIONS] -h, --host: Host server. -p, --port: Port server.

10. vacuumdb
Penjelasan: Meng-VACUUM satu atau semua database, mengklaim kembali storage yang terpakai dan memperbarui statistik planner.	
Cara pakai: vacuumdb [OPTIONS] [dbname] -z, --analyze: Menjalankan VACUUM dan ANALYZE. -F, --full: Melakukan VACUUM FULL (lebih lambat tapi menghemat lebih banyak space). -t, --table: Hanya memproses tabel tertentu.

11. reindexdb	
Penjelasan: Membangun ulang indeks pada satu atau semua database untuk meningkatkan performa atau mengatasi korupsi indeks.	
Cara pakai: reindexdb [OPTIONS] [dbname] -a, --all: Memproses semua database. -t, --table: Hanya membangun kembali indeks pada tabel tertentu.

12. clusterdb
Penjelasan: Meng-CLUSTER satu atau semua database berdasarkan indeks yang sudah ditentukan, mengurutkan data secara fisik.	
Cara pakai: clusterdb [OPTIONS] [dbname] -a, --all: Memproses semua database. -t, --table: Hanya memproses tabel tertentu.

13. pg_amcheck
Penjelasan: Memeriksa integritas struktur data pada indeks B-Tree dalam database. Digunakan untuk mendeteksi korupsi data tingkat rendah.	
Cara pakai: pg_amcheck [OPTIONS] [dbname] --all: Memeriksa semua database. --checksums: Memverifikasi checksum (jika diaktifkan).

14. pg_dump
Penjelasan: Membuat dump (backup) logis dari satu database. Output berupa script SQL atau format terkompresi.	
Cara pakai: pg_dump [OPTIONS] dbname -f, --file: File output backup. -F, --format: Format output (p plain, c custom, d directory, t tar). -C, --create: Sertakan perintah CREATE DATABASE. -a, --data-only: Hanya data, tanpa skema.

15. pg_dumpall
Penjelasan: Membuat dump logis dari SELURUH klaster, termasuk definisi role, tablespace, dan semua database.	
Cara pakai: pg_dumpall [OPTIONS] -f, --file: File output backup. -g, --globals-only: Hanya global object (role dan tablespace), tanpa data database.

16. pg_restore
Penjelasan: Memulihkan database dari file backup yang dibuat oleh pg_dump dalam format custom, tar, atau directory.	
Cara pakai: pg_restore [OPTIONS] filename -d, --dbname: Database target untuk dipulihkan. -c, --clean: Hapus objek sebelum membuat ulang. -j, --jobs: Menggunakan koneksi paralel untuk pemulihan cepat.

17. pg_basebackup
Penjelasan: Membuat backup level file sistem dari klaster database, digunakan untuk Point-In-Time Recovery (PITR) dan replikasi streaming.	
Cara pakai: pg_basebackup [OPTIONS] -D DATADIR -D: Direktori output untuk backup. -F, --format: Format output (p plain, t tar). -X, --wal-method: Metode untuk menyertakan WAL (misalnya stream).

18. pg_receivewal
Penjelasan: Digunakan pada Standby Server untuk menerima dan menyimpan Write-Ahead Log (WAL) dari Primary Server.	
Cara pakai: pg_receivewal [OPTIONS] -D: Direktori untuk menyimpan file WAL. -s, --status-interval: Interval pengiriman status ke Primary.

19. pg_recvlogical	
Penjelasan: Klien untuk Logical Decoding, digunakan untuk mengambil aliran data row-level dari Primary Server.	
Cara pakai: pg_recvlogical [OPTIONS] -d, --dbname: Database yang berisi slot replikasi logis. -S, --slot: Nama slot replikasi.

20. pg_rewind
Penjelasan: Alat untuk menyinkronkan klaster split-brain. Memungkinkan bekas Primary Server untuk bergabung kembali sebagai Standby setelah failover tanpa base backup penuh.	
Cara pakai: pg_rewind [OPTIONS] -D DATADIR --target-server='conn_string' -D: Data Directory lokal yang akan di-rewind.

21. pg_archivecleanup
Penjelasan: Alat yang digunakan untuk membersihkan file WAL lama dari arsip yang tidak lagi dibutuhkan oleh server Standby.	
Cara pakai: pg_archivecleanup [OPTIONS] archive_location oldest_wal_file

22. pg_verifybackup
Penjelasan: Memverifikasi integritas file backup yang dibuat dengan pg_basebackup.	
Cara pakai: pg_verifybackup [OPTIONS] directory

23. pg_config
Penjelasan: Menampilkan informasi tentang versi dan konfigurasi build PostgreSQL yang terinstal (jalur header, pustaka, dll.).	
Cara pakai: pg_config --bindir pg_config --version

24. pg_controldata
Penjelasan: Menampilkan informasi kontrol (control information) teknis yang disimpan di dalam klaster data. Berguna untuk pemecahan masalah.	
Cara pakai: pg_controldata -D DATADIR

25. pg_checksums
Penjelasan: Mengelola dan memverifikasi checksum halaman data. Dapat digunakan untuk mengaktifkan atau memverifikasi checksum pada klaster yang sudah ada.
Cara pakai: pg_checksums [OPTIONS] -D DATADIR --enable: Mengaktifkan checksum pada klaster yang dihentikan. --verify: Memeriksa checksum.

26. pg_resetwal
Penjelasan: Mengatur ulang informasi Write-Ahead Log (WAL). Ini adalah alat pemulihan darurat yang digunakan ketika server tidak dapat dimulai karena WAL yang rusak. Sangat berbahaya, gunakan sebagai upaya terakhir.	
Cara pakai: pg_resetwal -D DATADIR

27. pg_test_fsync
Penjelasan: Melakukan serangkaian tes untuk mengukur performa dan keandalan fsync() (sinkronisasi file sistem) pada disk Anda.	
Cara pakai: pg_test_fsync [OPTIONS]

28. pg_test_timing
Penjelasan: Mengukur overhead loop pengulangan dan panggilan sistem lainnya, penting untuk menentukan keakuratan waktu di server.	
Cara pakai: pg_test_timing

29. pg_upgrade
Penjelasan: Memfasilitasi pembaruan (upgrade) major version PostgreSQL dengan memindahkan atau menghubungkan file data tanpa dump dan restore penuh.	
Cara pakai: pg_upgrade [OPTIONS] -b, --old-bindir: Direktori binary PostgreSQL lama. -B, --new-bindir: Direktori binary PostgreSQL baru. -d, --old-datadir: Data Directory lama. -D, --new-datadir: Data Directory baru.

30. pg_waldump
Penjelasan: Utilitas untuk memeriksa dan menampilkan isi file WAL (Write-Ahead Log) dalam format yang dapat dibaca manusia. Berguna untuk debugging dan analisis.	
Cara pakai: pg_waldump [OPTIONS] -f, --file: File WAL yang akan ditampilkan. --start/--end: Batas waktu atau lokasi WAL yang akan ditampilkan.

31. ecpg
Penjelasan: Pre-prosesor SQL tertanam untuk C. Memungkinkan Anda menanamkan query SQL langsung ke dalam kode C.	
Cara pakai: ecpg [OPTIONS] filename.pgc


Menambahkan constraint pada table:
ALTER TABLE users ADD CONSTRAINT users_pk PRIMARY KEY (user_id);

Membuat PKEY dan FKEY untuk tabel baru:

Table acuan:
postgres = #

CREATE TABLE mandiri_period (
	id BIGINT
	,start_date TIMESTAMP WITH TIME zone
	,end_date TIMESTAMP WITH TIME zone
	,active boolean
	,selected boolean
	);

Tabel yang mereferensi:
postgres = #

CREATE TABLE mandiri_user_point (
	id BIGINT PRIMARY KEY
	,phone_number VARCHAR(15)
	,point BIGINT
	,NAME VARCHAR(100)
	,rank INT
	,user_id BIGINT
	,total_amount BIGINT
	,reward VARCHAR(50)
	,period_id BIGINT REFERENCES mandiri_period(id)
	);
    
Query untuk Grant:

- GRANT CONNECT:
GRANT CONNECT ON DATABASE nama_db TO nama_role;

- GRANT USAGE:
GRANT USAGE ON SCHEMA nama_schema TO nama_role;

- GRANT PRIVILEGE:
GRANT SELECT, DELETE, UPDATE ON nama_table TO nama_role; 

Query Untuk melihat user dan privilege:

SELECT grantee, table_schema, table_name, privilege_type
FROM information_schema.role_table_grants
WHERE grantee = 'support.iconcash'
AND table_name IN ('sec_activity', 'sec_user', 'account', 'customer');


install postgres: https://docs.google.com/document/d/1XfQbFsJgdamdi1gyYU8x6dKnJTem5KQGL98PbIfht50/edit?tab=t.0
Install telegraf: https://docs.influxdata.com/telegraf/v1/install/

Install pg-activity:
- sudo apt install pg-activity -y
Lalu jalankan dengan command:
- pg_activity -h nama_host -U nama_user -d nama_database -p nomor_port ---> pg_activity -h localhost -U pgsql -d postgres -p 5432

Setting pgbench untuk benchmark replication yang sudah dibuat
- pgbench -i -s 10 nama_database_kalian
Lalu jalankan dengan command:
- pgbench -c 10 -j 2 -T 60 nama_database_kaliann

Install Grafana-Server:
- sudo apt update
- sudo apt upgrade
- sudo apt install -y software-properties-common
- sudo add-apt-repository "deb https://packages.grafana.com/oss/deb stable main"
- sudo wget -q -O - https://packages.grafana.com/gpg.key | sudo apt-key add -
- sudo apt update
- sudo apt install Grafana
- sudo systemctl start grafana server
- sudo systemctl status grafana-server
- sudo systemctl enable grafana-server
- Buka di browser http://localhost:3000 atau http://ip_lokal:3000 missal (http://192.168.8.71:3000)
- Password: admin User:admin

Command Tmux:
Ctrl + b: Prefix untuk semua perintah tmux.
Manajemen Windows
Ctrl + b + c: Membuat window baru.
Ctrl + b + n: Pindah ke window berikutnya.
Ctrl + b + p: Pindah ke window sebelumnya.
Ctrl + b + &: Menutup window saat ini.
Manajemen Panes (Split)
Ctrl + b + ": Membagi window secara horizontal (membuat pane baru di bawah).
Ctrl + b + %: Membagi window secara vertikal (membuat pane baru di samping).
Ctrl + b + x: Menutup pane saat ini.
Ctrl + b + o: Pindah ke pane berikutnya.
Ctrl + b + {: Pindah pane ke kiri.
Ctrl + b + }: Pindah pane ke kanan.
Manajemen Sessions
Ctrl + b + d: Detach dari session saat ini.
tmux attach: Attach ke session tmux yang ada.
tmux ls: Menampilkan daftar sessions tmux yang sedang berjalan.
tmux new -s session_name: Membuat session baru dengan nama session_name.
tmux kill-session -t session_name: Menghentikan session dengan nama session_name.
Resizing Panes
Ctrl + b + :: Masuk ke command mode, ketik perintah manual (misalnya resize-pane).
Ctrl + b + Alt + Up/Down/Left/Right: Resize pane.
Copy Mode
Ctrl + b + [: Masuk ke copy mode (scroll atau memilih teks).
Space: Mulai memilih teks dalam copy mode.
Enter: Salin teks yang dipilih ke clipboard tmux.
Ctrl + b + ]: Paste teks yang telah disalin.
Miscellaneous
Ctrl + b + ?: Menampilkan semua shortcut tmux.
Ctrl + b + :: Membuka prompt untuk mengetik perintah tmux manual.

MEMBUAT LOGICAL REPLICATION CONNECT KE HA

config pg_hba untuk ip logical replication pada kedua HA server
config postgresql.conf pada logical
Listen_addresses = ‘*’
Aktifkan port
Wal_level = logical
archive_mode = on
archive_command = 'cp %p /equnix/wal/%f'
restartdb
buat publication pada master server
CREATE PUBLICATION nama_publication FOR TABLE nama_table;
grant jika role/user tidak memiliki akses/privillages
GRANT SELECT ON TABLE namatable TO namarole;
cek
SELECT * FROM pg_publication_tables WHERE pubname = 'my_publication';
buat database dan table beserta field yang ingin di replikasi di logical
buat subscription pada logical 
CREATE SUBSCRIPTION nama_subscription
CONNECTION 'host=vip_ip port=5432 user=namausername dbname=namadatabase password=namapassword'
PUBLICATION nama_publication;
jalankan kembali sudo /equnix/scripts/backup/equ_dbresync.sh pada standby server
Cek status pada keduanya untuk memastikan sudah berjalan dengan baik.
untuk master server
SELECT * FROM pg_replication_slots;
untuk logical server
SELECT * FROM pg_stat_subscription;

Query Untuk Cek privilege user dari information_schema.role_table_grants:

SELECT
    grantee,
    table_schema,
    table_name,
    privilege_type
FROM
    information_schema.role_table_grants
WHERE
    grantee = 'nama_user';


1. Script 11db.sh ---> /etc/init.d/11db.sh

WHO=whoami
PGUSER=pgsql
PGCTL=/equnix/apps/16/bin/pg_ctl
DTDIR=/equnix/data
LGSTR=${DTDIR}/startup.log

	 su - $PGUSER -c "$PGCTL -D $DTDIR -l $LGSTR $1";

2. Script 01_eqnx_connections.conf ---> /equnix/data/conf.d/

listen_addresses = '*'
port = 5432
max_connections = 5000
password_encryption = scram-sha-256

3. Script 02_eqnx_resources.conf

shared_buffers = 128MB
temp_buffers = 128MB
work_mem = 128MB
maintenance_work_mem = 1GB
effective_cache_size = 46GB
synchronous_commit = off
bgwriter_delay = 300
wal_writer_delay = 300
commit_delay = 200
min_wal_size = 1GB
max_wal_size = 3GB
full_page_writes = on
huge_pages = off
wal_buffers = 32MB
 
#shared_preload_libraries = 'pg_stat_statements'
#track_activity_query_size = 2048
#pg_stat_statements.max = 10000
#pg_stat_statements.track = all

4. Script 03_eqnx_replications.conf ---> /equnix/data/conf.d/

wal_level = logical
max_wal_senders = 10
wal_keep_size = 2048
hot_standby = on
checkpoint_completion_target = 0.9
max_replication_slots = 10
#max_standby_streaming_delay = 6h
#synchronous_standby_names =  	'someapps'
 
#REPLICATION
primary_conninfo = 'user=pgsql host=node1 port=5432'
recovery_target_timeline = 'latest'
promote_trigger_file = '/equnix/data/promote_standby'
restore_command = 'scp /equnix/archive/%f "%p"'
#restore_command = 'scp 172.26.20.9:/equnix/archive/%f %p'

5. Script 04_eqnx_logs.conf ---> /equnix/data/conf.d/

log_destination = stderr
logging_collector = on
log_directory = 'log'
log_filename = 'postgresql-%Y-%m-%d_%H%M%S.log'
log_min_duration_statement = 5000
log_line_prefix = '|%m|%r|%a|%d|%u|%p|%e|[%l]'
log_statement = 'ddl'
log_connections = on
log_disconnections = on

6. Script 05_eqnx_vacuums.conf ---> /equnix/data/conf.d/

autovacuum = on
#log_autovacuum_min_duration = 2000
#autovacuum_max_workers = 8
#autovacuum_vacuum_threshold = 500
autovacuum_analyze_threshold = 500

7. Script 06_eqnx_archives.conf ---> /equnix/data/conf.d/

#archive_mode = on
#archive_command = 'test ! -f /equnix/archive/%f && cp %p /equnix/archive/%f'
#archive_command = 'cd .'

8. Script 07_eqnx_ssl.conf ---> /equnix/data/conf.d/ 

#ssl = on
#ssl_ca_file = '/equnix/data/root.crt'
#ssl_cert_file = '/equnix/data/server.crt'
#ssl_crl_file = ''
#ssl_key_file = '/equnix/data/server.key'
#ssl_ciphers = 'HIGH:MEDIUM:+3DES:!aNULL' # allowed SSL ciphers
#ssl_prefer_server_ciphers = on

9. Script equ_dbresync.sh ---> /equnix/scripts/backup/

#!/bin/bash
# Copyright 2007-2022 Equnix Business Solutions,PT. All rights reserved
# Script compile by: Iyan Iskandar
# Developed by: Equnix Technical Team
# "-------------------------------------------------------------------"
# "|                  	Database Synchronization               	      |"
# "|                  	XL                                            |"
# "|                  	202208                                	      |"
# "-------------------------------------------------------------------"
#echo "---------------------- EQUNIX BUSINESS SOLUTIONS -----------------------";
#echo "|                                                                      |"
#echo "|                      	DB RESYNC SCRIPTS                             |"
#echo "|                                                                      |"
#echo "------------------------------------------------------------------------";
 
VIP=10.0.2.100
MASTER_HOST=node2
BINDIR=/equnix/apps/16/bin
PG_DATA_DIR=/equnix/data
PG_WAL_DIR=/equnix/wal
PG_TBLSPC1=/equnix/tblspc1
PG_TBLSPC2=/equnix/tblspc2
PG_PORT=5432
PG_USER=pgsql
OS_USER=pgsql
LOG_FILE=/equnix/scripts/logs/dbresync_$(date '+%Y%m%d').log
export PGPASSFILE='/equnix/scripts/.pgpass';
 
logger (){
    	# logger <message>
    	echo "$(date +'%F %T')|$(hostname)|$1" >> "$LOG_FILE";
}
 
dbexec(){
    	# dbexec <port> <query>
        $BINDIR/psql -At -h $MASTER_HOST -U $PG_USER postgres -p $PG_PORT -c "$1"
}
 
IS_NODE_MASTER=$(/usr/sbin/ip a | grep -c $VIP)
if [ "$IS_NODE_MASTER" -ge 1 ];
then
    	echo "---------------------- EQUNIX BUSINESS SOLUTIONS -----------------------";
    	echo "|                                                                       |"
	echo "|   	Warning!!! Virtual IP is exists this node is primary!         |"
	echo "|                                                                       |"
	echo "------------------------------------------------------------------------";
	exit 0;
fi

if [ -f $PG_DATA_DIR/promote_standby ]; then
	logger "Removing trigger_file on this nodes $(hostname)";
	rm $PG_DATA_DIR/activate_standby
fi;

logger "Following Master on $MASTER_HOST:$PG_PORT";
logger "Stopping Service 11DB/Postgres";
PGPID=$(pgrep postgres -c);
if [ -n "$PGPID" ]; then
	/etc/init.d/11db.sh stop
fi;

echo "resynchronize WAL -----------------------------------------------";
logger "Starting Synchronize WAL";
su - $OS_USER -c "rsync -argv --progress --delete $OS_USER@$MASTER_HOST:$PG_WAL_DIR/ $PG_WAL_DIR/"
logger "Synchronizing WAL done";

logger "Executing start backup on resynchronized DB)";
logger "$(dbexec "SELECT pg_start_backup('db_resync',true)")";

echo "Resynchronize whole Data Directory ------------------------------";
su - $OS_USER -c "rsync -arg $OS_USER@$MASTER_HOST:$PG_DATA_DIR/global/pg_control $PG_DATA_DIR/global/;"
su - $OS_USER -c "rsync -arg --delete --progress \
	--exclude=pg_control \
	--exclude=pg_wal \
	--exclude=log \
	--exclude=standby.signal \
	--exclude=postgresql.conf \
	--exclude=pg_hba.conf \
	--exclude=conf.d \
	--exclude=postmaster.pid \
	$OS_USER@$MASTER_HOST:$PG_DATA_DIR/ $PG_DATA_DIR/"
	logger "Synchronizing data directory done";

#echo "Resynchronize Tablespace Directory ------------------------------";
#su - $OS_USER -c "rsync -arg --delete --progress $OS_USER@$MASTER_HOST:$PG_TBLSPC1/ $PG_TBLSPC1/"
#su - $OS_USER -c "rsync -arg --delete --progress $OS_USER@$MASTER_HOST:$PG_TBLSPC2/ $PG_TBLSPC2/"

echo "Stopping backup ----------------------------------------------------";
logger "Executing stop backup on resynchronized DB ";
logger "$(dbexec 'SELECT pg_stop_backup()')";

echo "Resynchronize WAL Directory -----------------------------";
su - $OS_USER -c "rsync -argv --progress $OS_USER@$MASTER_HOST:$PG_WAL_DIR/ $PG_WAL_DIR/;"
logger "Synchronizing WAL done";

echo "Creating standby.signal ----------------------------------";
if [ ! -e $PG_DATA_DIR/standby.signal ]; then
	logger "Creating standby.signal";
	touch $PG_DATA_DIR/standby.signal;
else
	logger "File standby.signal is exists";
fi;

echo "Starting 11DB/Postgres Service -----------------------------------";
/etc/init.d/11db.sh start;
PGPID=$(pgrep postgres -c);
if [ -n "$PGPID" ]; then
	logger "11DB/Postgres Started";
fi;

logger "Checking replication status from Master Server)";
sleep 5;
logger "$(dbexec "SELECT client_addr,sync_state FROM pg_stat_replication")"
exit 0;

10. Script equ_activate_standby.sh ---> /equnix/scripts/ha/

LOG_FILE=/equnix/scripts/logs/promote_$(date +%F).log
case $1 in
start)
	echo "$(date '+%F %T')|$(hostname)|promoting standby server" >> "$LOG_FILE"
        touch /equnix/data/promote_standby
	exit 0
;;
*)
        exit 0;
esac;

11. Script equ_forced_failover.sh ---> /equnix/scripts/ha/

#!/bin/bash
# Copyright 2007-2022 Equnix Business Solutions,PT. All rights reserved
# Script compile by: Iyan Iskandar
# Developed by: Equnix Technical Team
# "-------------------------------------------------------------------------";
# "|                      FORCE FAILOVER SCRIPTS                            |"
# "|                      INTERNAL                                          |"
# "|                      202208                                            |"
#  "------------------------------------------------------------------------";
#CLIENT="INTERNAL"
PRIVATE_PEER=192.168.56.80
#PRIVATE_PEER=10.1.1.4
PGUSER=pgsql 
OSUSER=pgsql
PEER_NODE=node2
PGDATADIR=/equnix/data
DBPORT=5432
SSHPORT=22
LOGFILE=/equnix/scripts/logs/forced_failover_$(date +%Y%m%d).log

# EmailAccount
#DSTM="support@equnix.asia"
#MAIL_FILE=/tmp/forced_failover

# Function
#send_mail_alert() {
#    {
#        echo "Importance: HIGH" 
#        echo "" 
#        echo "Dear Team," 
#        echo ""
#        echo "$HOSTNAME has executed FAILOVER and became MASTER on $(date +'%F %T')." 
#        echo "Please check PostgreSQL instance instance and Virtual IP acquisition on server $HOSTNAME."
#        echo "--------------------------------"
#        echo " PostgreSQL Processes"
#	sudo pgrep -a postgres| head -n 50
#	sleep 2;
#        echo "IP Address Check"
#        ip addr;
#        echo "--------------------------------"
#        echo ""
#        echo "Thank you." 
#    } > "$MAIL_FILE";
#    /usr/bin/mail -s "[ $CLIENT ] $HOSTNAME FAILOVER ALERT $(date +'%F %T')" "$DSTM" < "$MAIL_FILE";
#}

logger() {
	echo "$(date '+%F %T')|$(hostname)|$1" >> "$LOGFILE"	
}

case $1 in
start)
	if [ -e $PGDATADIR/standby.signal ]; then
    		if [ "$(/usr/bin/ping -c 1 $PRIVATE_PEER -W 1 | grep -c "bytes from")" -gt 0 ]; then
	        	logger "Attempt to cluster standby Master Node through PRIVATE IP: $PRIVATE_PEER";
		       	su - $OSUSER -c "ssh -p $SSHPORT -o ConnectTimeout=3 -o ConnectionAttempts=1 -t $PRIVATE_PEER \"sudo /equnix/scripts/HA_master/equ_exec_failover.sh\"";
        		logger "Master Node has been clustered standby properly!";
    		else
        		logger "Attempt to reboot Master Node through PUBLIC IP: $PUBLIC_PEER";
	       		su - $OSUSER -c "ssh -p $SSHPORT -o ConnectTimeout=3 -o ConnectionAttempts=1 -t $PUBLIC_PEER \"sudo /equnix/scripts/HA_master/equ_exec_failover.sh\"";
        		echo "Master Node has been clustered standby properly!";
		fi
		/usr/sbin/pcs node standby $PEER_NODE	
        	logger "Promoting PostgreSQL $HOSTNAME";
	       	/equnix/scripts/ha/equ_activate_standby.sh start
        	logger "Promoting $HOSTNAME Complete and become MASTER now!";
#	       	send_mail_alert;
 #       	logger "Email mailforcedfailoversent";
		exit 0;
	else
		echo "The $HOSTNAME is NOT in Standby Mode!";
    		exit 0;
    	fi;
	;;
*)
    	exit 0;
esac;

12. Script equ_db_check.sh ---> /equnix/scripts/ha/

#!/bin/bash
# Copyright 2007-2022 Equnix Business Solutions,PT. All rights reserved
# Script compile by: Iyan Iskandar
# Developed by: Equnix Technical Team
# "-------------------------------------------------------------------------";
# "|                      DBCHEK SCRIPTS                                    |"
# "|                      INTERNAL                                          |"
# "|                      202208                                            |"
#  "------------------------------------------------------------------------";

#CLIENT="INTERNAL"
BINDIR=/equnix/apps/16/bin
PGDATADIR=/equnix/data
PEER_HOSTN=node2
PEER_NODE=192.168.56.80
LOGFILE=/equnix/scripts/logs/dbcheck_$(date '+%Y%m').log
#MAILFILE=/tmp/maildbcheck
#MAIL_DEST="fauzan@equnix.asia"
FLAGS="/tmp/peerdown"

# Connection Parameter
PGUSER=pgsql
OSUSER=pgsql
DBPORT=5432
SSHPORT=22
export PGPASSFILE=/equnix/scripts/.pgpass

logger (){
        echo "$(date +'%F %T')|$(hostname)|$1" >> "$LOGFILE";
}

#fsendmail () {
#        {
#                echo "================================"
#                date
#                echo "================================"
#                echo -e "Importance: MEDIUM\n"
#                echo -e "Dear Team,\n"
#                echo "$2"
#                echo -e "\nThank you."
#        } > $MAILFILE-"$1"
#        /usr/bin/mail -s "[ $CLIENT ] Instance $1 has down" $MAIL_DEST < $MAILFILE-"$1";
#        logger "Email $MAILFILE-$1 sent";
#}

instance_check(){
        /usr/bin/netstat -ltpn | grep postgres | grep -c $DBPORT
}

is_standby_ready(){
	su - $OSUSER -c "ssh -p $SSHPORT -o ConnectTimeout=3 -o ConnectionAttempts=1 -t $PEER_NODE \"sudo /usr/bin/netstat -lptn | grep postgres\"" | grep -c $DBPORT	
}

dbexec(){
        $BINDIR/psql -At -h 127.0.0.1 -U $PGUSER postgres -p $DBPORT -c "$1"
}

restartdb(){
        /etc/init.d/11db.sh restart
}

check_master() {
        IS_MASTER_UP=$(instance_check);
        if [ "$IS_MASTER_UP" -eq 0 ]; then
                logger "Restarting Service 11DB/Postgres"
                restartdb;
                logger "Rechecking MASTER 11DB/Postgres service on $HOSTNAME after restart";
                sleep 5;
                RECHECK_MASTER=$(instance_check);
                if [ "$RECHECK_MASTER" -ge 1 ]; then
                        logger "11DB/Postgres has been restarted successfully"
                else
                        IS_STANDBY_READY=$(is_standby_ready);
                        if [ "$IS_STANDBY_READY" -eq 0 ]; then
                                logger "Standby Server not ready for failover, exiting"
                                exit 0;
                        else
                                logger "Failovering to Standby Server"
                                fsendmail master "$(echo -e\
                                "PostgreSQL Instance in server $(hostname) failed to be restarted on $(date +'%F %T').\nFailover should happened and please check Failover process on Standby Node.\n\n")"
                                /usr/sbin/pcs node standby;
                                exit 0;
                        fi;
                        exit 0;
                fi;
        else
                logger "Master $(hostname) 11DB/Postgres instance is running"
        fi;
}

check_standby() {
        PEER=$(sudo /usr/sbin/pcs status | grep $PEER_HOSTN | grep -c 'standby\|OFFLINE');
        if [ "$PEER" -ge 1 ];then
                logger "Cluster standby in offline mode, please check cluster";
                exit 0;
        else
		IS_REPS_UP=$(dbexec "SELECT 1 FROM pg_stat_replication WHERE client_addr='${PEER_NODE}' AND state='streaming'");
		if [ "$?" -eq 0 ];then
			if [ "$IS_REPS_UP" != 1 ]; then
                                logger "Standby PostgreSQL service is NOT running!!!";
                                if [ ! -e $FLAGS ]; then
                                        touch $FLAGS;
                                        logger "Sending email due to lost replication to Standby Instance";
                                        fsendmail standby "$(echo -e\
                                               "PostgreSQL Instance on $PEER_HOSTN has down.\nReplication from $(hostname) to ${PEER_HOSTN} instance has been disconnected on $(date +'%F %T').\nPlease check Standby Node immediately")"
                                        logger "Set cluster standby on Standby server";
                                        /usr/sbin/pcs node standby $PEER_HOSTN;
                                        exit 0;
                                fi;
                        else
                                logger "Standby instance is running"
                                rm -f $FLAGS;
                        fi;
		else
			logger "Connection to Database failed, skipping"
                fi;
	fi
}

case $1 in
status)
        if [ ! -e "$PGDATADIR"/standby.signal ]; then
                logger "---------------------------------------------------"
                check_master;
		check_standby;
                exit 0;
        fi;
	exit 0;
;;

*)
	exit 0;
;;

esac;
exit 0;

13. Script equ_exec_failover.sh ---> /equnix/scripts/ha/

LOGFILE=/equnix/scripts/logs/exec_failover_$(date +%Y%m).log
logger (){
        # logger <message>
        echo "$(date +'%F %T')|$(hostname)|$1" >> "$LOGFILE";
}
logger "killing local PostgreSQL instances $HOSTNAME"
for i in $(/usr/bin/netstat -lpnt | grep postgres|grep -v tcp6| awk '{print $7}'| awk -F '/' '{print $1}');
	do kill -9 "$i";
done
logger "Failover executed $HOSTNAME"
/sbin/reboot
exit 0

14. Script pgpass ---> /equnix/scripts/.pgpass

10.0.2.31:5432:postgres:pgsql:pgsql #ip node1 (Contoh)
10.0.2.32:5432:postgres:pgsql:pgsql #ip node2
10.0.2.33:5432:postgres:pgsql:pgsql #ip node3 (logical)

15. Menyiapkan 3 hal ini: 
a. 3 IP Public should be prepared and and 2 IP Private
b. UDP connections should be opened for port 5404 and 5405
c. TCP connections should be opened for port 2224
- #sudo iptables -A INPUT -p udp --dport 5404 -j ACCEPT
- #sudo iptables -A INPUT -p udp --dport 5405 -j ACCEPT
- #sudo iptables -A INPUT -p tcp --dport 2224 -j ACCEPT


cek privileged user:
select grantor, grantee, table_schema, table_name, privilege_type from information_schema.role_table_grants where grantee = 'nama_user';

postgres=# \d information_schema.role_table_grants 
                     View "information_schema.role_table_grants"
     Column     |               Type                | Collation | Nullable | Default 
----------------+-----------------------------------+-----------+----------+---------
 grantor        | information_schema.sql_identifier |           |          | 
 grantee        | information_schema.sql_identifier |           |          | 
 table_catalog  | information_schema.sql_identifier |           |          | 
 table_schema   | information_schema.sql_identifier |           |          | 
 table_name     | information_schema.sql_identifier |           |          | 
 privilege_type | information_schema.character_data |           |          | 
 is_grantable   | information_schema.yes_or_no      |           |          | 
 with_hierarchy | information_schema.yes_or_no      |           |          | 

#Hal yang perlu diubah di script jika menggunakan Postgres16
1. wal_keep_segments diubah ke wal_keep_size 
2. promote_trigger_file dihapus


POSTGRESQL NOTES:
DOKUMENTASI POSTGRESQL: https://www.postgresql.org/docs/current/

INSTALASI POSTGRES:
1. Menginstall development tools dan dependencies
#sudo apt-get install build-essential libreadline-dev zlib1g-dev flex bison libxml2-dev libxslt-dev libssl-dev libxml2-utils xsltproc pkgconf ccache 
Build-essential: paket meta di sistem berbasis Debian yang mencakup berbagai paket yang sangat penting untuk membangun perangkat lunak daris source code seperti GNU C++ compiler dan Make.

Pada system RHEL/Centos/Alma/ gunakan perintah berikut:
#sudo dnf install -y gcc gcc-c++ readline-devel zlib-devel flex bison libxml2-devel libxslt-devel openssl-devel libicu-devel pkgconf ccache

2. Mendownload source code dari website postgresql
Mendownload source code dari ftp postgresql dengan perintah wget(ini versi 12.16)
#wget https://ftp.postgresql.org/pub/source/v12.16/postgresql-12.16.tar.gz

3. Ekstrak tarball
#tar xvfz postgresql-12.16.tar.gz

4. Pindah ke direktori yang postgresql-12.16 dan buat direktori untuk penginstalan
# cd postgresql-12.8
# sudo mkdir -p /equnix/apps/12

5. Compile dan arahkan kompliasi ke direktori yang sudah dibuat
#./configure --prefix=/equnix/apps/12 Tujuan untuk melakukan konfigurasi instalasi dengan target pemasangan adalah direktori tersebut. note: kalau gagal saat configure lihat dulu muncul error apa, install terlebih dahulu dependecies yang dibutuhkan
# make proses "kompilasi kode sumber"
# make install  "proses pemasangan file hasil kompilasi ke sistem agar dapat digunakan oleh pengguna dan aplikasi lain."

6. Buat user pgsql
#adduser pgsql

7. Buat direktori untuk data dan write-ahead log(wal) dan set pemilik ke pgsql
#sudo mkdir -p /equnix/data
#sudo mkdir -p /equnix/wal
#sudo chown -R pgsql. /equnix/data
#sudo chown -R pgsql. /equnix/wal

8. Tambahkan direktori /equnix/apps/12/bin ke variabel PATH
#echo 'export PATH=$PATH:/equnix/apps/12/bin' >> ~/.bashrc
source ~/.bashrc

9. Ganti ke user pgsql
#su pgsql

10. Initialisasi PostgreSQL database cluster
#/equnix/apps/12/bin/initdb -D /equnix/data -X /equnix/wal -U pgsql

11. Pindah ke /equnix/data dan ganti nama pg_wal ke pg_wal_old
#cd /equnix/data
#mv pg_wal pg_wal_old

12. Buat symlink ke /equnix/wal dan pindahkan isi pg_wal_old ke sana 
#ln -s /equnix/wal pg_wal
#mv pg_wal_old/* pg_wal
#rm pg_wal_old

13. Pindah ke /equnix/apps/12/bin dan mulai postgresql
$cd /equnix/apps/12/bin/
$/equnix/apps/12/bin/pg_ctl -D /equnix/data/ -l /equnix/data/logfile start

14. Masuk ke postgres
/equnix/apps/12/bin/psql -U pgsql postgres -p 5432


POSTGRES QUERY:

1. SELECT DISTINCT: 
- Untuk menampilkan values yang berbeda dalam sebuah column, misal dalam column membership terdapat jenis member Gold, Platinum, dan Silver. Query distincti akan mengambil values dari column membership yang berbeda saja sebagai berikut:
SELECT kolom1, kolom2 FROM nama_tabel;

2. SELECT COUNT
- Untuk menghitung berapa values dalam satu column, misal dalam satu column ada 5 values maka ketika menjalankan query berikut:
SELECT COUNT (nama_kolom) FROM nama_tabel; maka akan menghasilkan output seperti ini:

supermarket=> select count (membership) from customer;
 count
-------
     3
(1 row)

3. Klausa WHERE
- Sebagai filter untuk mencari, menghapus, atau menambahkan value pada sebuah tabel berdasarkan kriteria tertentu, misal mencari nama_pelanggan dengan membership gold maka seperti ini:

SELECT nama_pelanggan FROM customer WHERE membership = 'Gold';

4. ORDER BY Keyword
- Untuk memfilter hasil pencarian berdasarkan kriteria urutan, urutan angka atau alphabet seperti ini:
SELECT * FROM customer ORDER BY customer_id ASC | DESC; 
SELECT * FROM customer ORDER BY customer_id ASC, membership DESC;

5. Klausa LIMIT
- Untuk membatasi data yang ditampilkan misal hanya ingin ambil 10 saja maka seperti ini:
SELECT * FROM customer LIMIT 10;

Klausa OFFSET
- Untk memulai menampilkan data diatas values yang diberikan, jadi values pertama dimulai dari 0, jika menggunakan OFFSET misal OFFSET 40 artinya data yang dtiampilkan mulai dari 41:
SELECT * FROM customer OFFSET customer_id  2;

Gabungan Klausa LIMIT dan OFFSET:
- Untuk mengambil data dengan limit tertentu dimulai dari nilai tertentu. Misal hanya ingin mengamil 10 values dengan values dimulai dari 91 maka seperti ini:
SELECT customer_id FROM customer LIMIT 10 OFFSET 90; 

6. Klausa MIN MAX (Nilai NULL diabaikan)
- Untuk mengambil nilai terbesar atau terkecil dalam sebuah kolom:
SELECT MIN/MAX(price) FROM tabel_harga; maka akan muncul nilai paling kecil atau berdasarkan

7. Klausa SUM (Nilai NULL diabaikan)
- Untuk menjumlahkan nilai int di sebuah kolom, misal kolom satu terdiri dari 3 baris dengan nilai 1 maka dapat dijumlahkan nilai pada kolom tersbut dan hasilnya 3 seperti ini:
SELECT SUM(customer_id) FROM customer;

8. Klausa AVG (Nilai NULL diabaikan)
- Untuk menjumlahkan nilai int di sebuah kolom lalu menghasilkan nilai rata-rata:
SELECT AVG(harga) FROM tabel_barang:

- Tambahkan numeric setelah colom untuk membulatkan hasil rata rata seperti ini:
SELECT AVG(harga)::numeric FROM tabel_barang:

9. Klausa LIKE
- Untuk mencari value dengan pola tertentu, digunakan bersamaan dengan klausa WHERE:
SELECT * FROM customer WHERE nama_pelanggan LIKE 'An%'; simbol persen bertujuan untuk mencari pola yang mirip seperti itu misal hasil query tersebut seperti ini:
 customer_id | nama_pelanggan  | membership
-------------+-----------------+------------
           2 | Andhika Pratama | Platinum
           4 | Anjasmara       |
(2 rows)

- Pola %a% berarti mengambil nilai yang mengandung karakter a
- LIKE itu case sensitive, sedangkan ILIKE tidak
- a% berarti mencari string yang berawalan a
- %a berarti mencari string yang berakhiran a
- Underscore _ untuk mencari string yang hanya diingat beberapa karakternya saja misal 'L_in_d_'

10. Klausa IN
- Untuk mencari values berdasarkan kolom lain, misal dalam sebuah tabel ada 2 kolom yaitu nama dan ras, kita ingin mengambil nama seseorang berdasarkan ras mereka misalnya ras batak, maka jalankan query sebagai berikut: 
SELECT kolom_1 FROM nama_tabel WHERE kolom_2 IN ('kriteria'); 

-Contoh
SELECT nama FROM penduduk WHERE ras IN ('Batak', 'Sunda');

- Menggunakan IN (SELECT)
Untuk mencari values berdasarkan kolom lain yang berada pada tabel lain seperti ini:
SELECT nama FROM penduduk WHERE suku IN (SELECT nama_suku FROM suku);

- Menggunakan NOT IN (SELECT)
Untuk mencari values berdasarkan kolom lain yang dikecualikan yang berada pada tabel lain seperti ini:
SELECT nama FROM penduduk WHERE suku IN (SELECT nama_suku FROM suku WHERE nama_suku = 'Minang');

11. Klausa BETWEEN
- Untuk mencari values berdasarkan interval tertentu misal antara 1 dan 7 tetapi nila awal dan akhir dimasukan:
SELECT nama_karyawan FROM employees WHERE id_karyawan BETWEEN 1 AND 7;

- BETWEEN dengan Text, maka hasilnya akan menampilkan nilai alphabet 
SELECT nama_karyawan FROM employees WHERE id_karyawan BETWEEN 'Andi' AND 'Cahya';

- BETWEEN dengan date, maka hasilnya akan menampilkan nilai tanggal:
SELECT * FROM orders
WHERE order_date BETWEEN '2023-04-12' AND '2023-05-05';

12. Klausa AS
- Untuk membuat sebuah alias untuk menggantikan nama tabel atau nama kolom agar lebih mudah dibaca. Durasi penggunaan AS hanya sementara yaitu sepanjang query tersebut berjalan saja:
SELECT id_karyawan AS id, nama_karyawan AS nama FROM employees;
 
 atau seperti ini, tanpa AS pun hasilnya sama:

 SELECT id_karyawan AS id, nama_karyawan AS nama FROM employees;

- Menggabungkan dua kolom dan dibuat alias seperti ini gunaka simbol || :
SELECT id_karyawan, nama_karyawan || AS nama FROM employees;


- Menggunakan alias dengan spasi seperti ini:
SELECT nama_karyawan AS "Nama Karyawan Terbaik" FROM employees;

13. Klausa JOIN
- Untuk menggabungkan kolom dari dua/lebih tabel yang berbeda untuk menjadi satu berdasarkan satu kolom yang memiliki kesamaan umumnya primary key dan foreign key. Misal ada dua tabel sebagai berikut

14. Query Untuk Mengecek Table dan User apa saja yang mengakses tabel tersebut:
SELECT grantee, privilege_type
FROM information_schema.role_table_grants
WHERE table_schema = 'public'  -- ganti sesuai schema
  AND table_name = 'nama_tabel';

15. Menghapus Proses Menggunakan PID
SELECT pg_terminate_backend(backend_process_id);

16. Membuat Table Partisi
#Tabel yg akan dipartisi
- CREATE TABLE nama_table (kolom type) partition by range (kolom_yg_akan_dipartisi);

#Tabel yang akan menjadi partisi
- CREATE TABLE nama_table_partisi partition from table_yg_dipartisi from (tgl) to (tgl);

POSTGRESQL BACKUP:

1. pg_dump
Untuk backup satu database saja atau bisa juga tabel tertentu. Untuk lebih lengkap lihat pg_dump --help 
Jalankan command psql -U pgsql -d namadb_yg_dibackup -p port_db_yg_dibackup -Fc/p >> nama_file_hasil_backup (c untuk format custom binary sedangkan p untuk text sql)

2. pg_dumpall
Untuk backup satu cluster (database, role, schema). Bisa untuk backup salah satu saja. Lebih lengkap lihat di pg_dumpall --help
Jalankan command: pg_dumpall -U pgsql -p portdb_yg_dibackup -f nama_file_hasil_backup 

LINUX NOTES:

LINUX COMMAND

1. AWK
- Menganalisa pola dan memproses bahasa

- Untuk mengambil kolom dari sebuah file dapat dilakukan seperti berikut:

Misal nama file adalah file_123 dengan isi file seperti ini lalu ingin mengambil kolom 1 yang berisi angka 1 saja maka seperti ini:
12345 6789
12345 6789
12345 6789
12345 6789

awk '{print $1}' file_123 maka akan mengambil kolom pertaama atau kata pertama
awk -F "2" '{print $1}' file_123
Jadi -F itu digunakan sebagai separator antara kolom yang satu dan lainnya
Lalu -v untuk menambahkan variabel kedalam output dari kolom, misal isi file_123 adalah:
Nama,Umur,Status
John,25,Single
Anna,30,Married
Mike,22,Single

Lalu misal kita ingin mengambil kolom umur tapi ingin menambah variabel 'Usia' untuk kolom tersebut maka command seperti berikut:
#awk -F , -v var="Usia:" '{print var, $2}' file_123

2. Membuat Tethering/AP (Access Point) di Linux
- Cek apakah perangkat wifi mendukuung AP dengan command 
#iw list

- Install dependecies 
#sudo apt install util-linux hostapd iproute2 iw dnsmasq iptables

- Install create_ap
#git clone https://github.com/oblique/create_ap
#cd create_ap
#sudo make install 

- Jalankan command:
#sudo create_ap nama_interface_wifi nama_interface_wifi nama_ssid_yg_diinginkan password_8_karakter 
Contoh:
#sudo create_ap wlp2s0 wlp2s0 Equnix 12345678 (share dari WiFi ke WiFi. Untuk nama interface dapat dicek melalui ip a. Cari interface wifi berawalan huruf w)
#sudo create_ap wlan0 eth0 nama_ssid password_wifi (share koneksi dari LAN (eth0) ke wireless (wlan0))
#sudo create_ap wlan0 ppp0 nama_ssid password_wifi (share koneksi dari modem)

1. Membuat Gateway Server dengan IP Forwarding dan NAT menggunakan nftables

a) Setup VM Gateway/Jumphost (VM yang akan menjadi Gateway (Umumnya Menjadi Jumphost))
- Adapter 1: Bridge (Untuk internet)
- Adapter 2: Internal Network (misal inet)
- Edit /etc/network/interfaces
    # Internet (Bridge)
    auto eth0 (nama interface yg untuk terima internet. Dapat disesuaikan)
    iface eth0 inet dhcp

    # Jaringan Internal (static)
    auto eth1
    iface eth1 inet static
    address 10.0.0.1
    netmask 255.255.255.0

- #sudo systemctl restart networking (restart network)

b) Setup VM Client (Client yang akan memiliki jaringan internal)
- Adapter 1: Internal Adapter Inet (adapter yang sama dengan yang digunakan di gateway server)
- Setting IP inet:
- #vim /etc/network/interfaces
    auto eth1 (nama interfaces)
    iface eth1 inet static
    address 10.0.0.2
    netmask 255.255.255.0
    gateway 10.0.0.1 (ip yg ada di Gateway server)
    dns-nameserver 8.8.8.8 (agar bisa ping ke 8.8.8.8)
- #sudo systemctl restart networking

c) Aktifkan IP Forwarding di Gateway Server
- #sudo sysctl -w net.ipv4.ip_forward=1
- Edit permanen di /etc/sysctl.conf lalu cari line diatas dan uncommand
- #sudo sysctl -p

d) Konfigurasi nftables di Gateway Server
#NAT Table
- #sudo nft flush ruleset (ini hanya untuk reset setting yang sudah ada saja)
- #sudo nft add table ip nat
- #sudo nft 'add chain ip nat postrouting {type nat hook postrouting priority 100;}'
- #sudo nft add rule ip nat postrouting oif "eth0" masquerade

#Filter Table
- #sudo nft add table ip filter
- #sudo nft 'add chain ip filter forward { type filter hook forward priority 0 ; }'
- #sudo nft add rule ip filter forward iif "eth1" oif "eth0" accept
- #sudo nft add rule ip filter forward iif "eth0" oif "eth1" ct state established,related accept

e) Testing
- Dari VM Client → ping 10.0.0.1 → pastikan bisa.
- Dari VM Client → ping 8.8.8.8 → internet via gateway.
- Dari VM Client → ping google.com → pastikan DNS berjalan.

f) Buat Persisten (Opsional)
Simpan aturan nftables:
- #sudo sh -c 'nft list ruleset > /etc/nftables.conf'

 Aktifkan service agar otomatis load saat boot:
- #sudo systemctl enable nftables
- sudo systemctl start nftables





